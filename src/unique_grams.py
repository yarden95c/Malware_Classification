from csv import DictReader
from datetime import datetime
import pickle
import heapq
import os
import sys

data_folder = "Data"
train_path = "Data/train"
test_path = "Data/test"
csv_path = "trainLabels.csv"

def load_label(path, label):
    result = []
    train_files = os.listdir(train_path)
    train_files = [os.path.splitext(x)[0] for x in train_files]
    for row in DictReader(open(path)):
        if int(row['Class']) == label and train_path.__contains__(row['Id']):
            result.append((row['Id']))
    return result


# generate grams dictionary for one file
def grams_dict(f_name, N=4):
    path = "{}/{}.bytes".format(train_path, f_name)
    #print("path is %s" % path)
    one_list = []
    with open(path, 'rb') as f:
        for line in f:
            one_list += line.rstrip().split(" ")[1:]
    grams_string = [''.join(one_list[i:i + N]) for i in range(len(one_list) - N + 1)]
    tree = dict()
    for gram in grams_string:
        if gram not in tree:
            tree[gram] = 1
    return tree


# add up ngram dictionaries
def reduce_dict(f_labels):
    print ("inside reduce_dict")
    result = dict()
    for f_name in f_labels:
        d = grams_dict(f_name)
        for k, v in d.iteritems():
            if k in result:
                result[k] += v
            else:
                result[k] = v
        del d
    # pickle.dump(result, open('gram/ngram_%i'%label,'wb'))
    return result


# heap to get the top 100,000 features.
def Heap_top(dictionary, label, num=100000):
    heap = [(0, 'tmp')] * num  # initialize the heap
    root = heap[0]
    for ngram, count in dictionary.iteritems():
        if count > root[0]:
            root = heapq.heapreplace(heap, (count, ngram))
    filepath = 'gram/ngram_%i_top%i' % (label, num)
    pickle.dump(heap, open(filepath, 'wb'))

def update_pathes():
    global data_folder, train_path, test_path, csv_path
    with open('path.txt', 'r') as f:
        data_folder = f.readline().replace('\r','').replace('\n','')
        train_path = f.readline().replace('\r','').replace('\n','')
        test_path = f.readline().replace('\r','').replace('\n','')
        csv_path = f.readline().replace('\r','').replace('\n','')


if __name__ == '__main__':

    start = datetime.now()
    # for label in range(1,10): # take too much memory
    label = int(sys.argv[1])
    update_pathes()
    #f_label = all the files name in class label
    f_labels = load_label(csv_path, label)
    if f_labels.__len__()!= 0:
        print("Gathering 4 grams, Class %i out of 9... " % label)
        print ("num of files from that label is: %i"  % f_labels.__len__())
        Heap_top(reduce_dict(f_labels), label)
        print (datetime.now() - start)